```{r}
studentPerf <- read.csv("StudentsPerformance.csv")
```



Analyse descriptive

Ici "gender" est une variable binaire, "race.ethnicity", "parental.level.of.education", "lunch" et "test.preparation.course" sont des variables qualitative nominales
Les variables "math.score", "reading.score", "writing.score" sont quantitatives discrètes.
```{r}
summary(studentPerf)
```

Nous remarquons qu'il n'y a pas de valeurs manquantes dans ce jeu de données.

Les scores aux trois épreuves "math.score", reading.score" et "writing.score" varient respectivement dans [[0;100]], [[17;100]] et [[10;100]].
```{r}
levels(studentPerf$gender)
```
"gender" varie entre "female" et "male", c'est donc une variable binaire
```{r}
levels(studentPerf$lunch)
```
"lunch" varie entre "free/reduced" et "standard"
```{r}
levels(studentPerf$race.ethnicity)
```
"race.ethnicity" varie entre "group A", "group B", "group C", "group D" et "group E"
```{r}
levels(studentPerf$parental.level.of.education)
```
"parental.level.of.education" varie entre "associate's degree", "bachelor's degree", "high school", "master's degree", "some college" et "some high school"  


Nous étudions maintenant les liens statistiques entre les différentes variables.

Analyses multivariées 

Tests préalables : Test de normalité et d'homoscédasticité
1)Test de normalité
On vérifie que les données sont gaussiennes
```{r}
hist(studentPerf$math.score,prob=T, main = "Histogram of math.score", xlab = "math.score")
curve(dnorm(x,mean(studentPerf$math.score),sd(studentPerf$math.score)), add=T,col="red")
```
```{r}
hist(studentPerf$reading.score,prob=T,main = "Histogram of reading.score", xlab = "reading.score")
curve(dnorm(x,mean(studentPerf$reading.score),sd(studentPerf$reading.score)), add=T,col="red")
```
```{r}
hist(studentPerf$writing.score,prob=T,main = "Histogram of writing.score", xlab = "writing.score")
curve(dnorm(x,mean(studentPerf$writing.score),sd(studentPerf$writing.score)), add=T,col="red")
```

Les données semblent être gaussiennes, nous effectuons alors un test de normalité afin de le vérifier.
La taille de l'échantillon (1000 individus) est petite (<2000). Le test de Shapiro-Wilk est donc adaptée.

```{r}
shapiro.test(studentPerf$math.score)
```
Le test de Shapiro-Wilk donne une probabilité de dépassement de 0.0001455, inférieure au seuil de signification de 5%. L'hypothèse de normalité de math.score est donc rejetée.
```{r}
shapiro.test(studentPerf$reading.score)
```
Le test de Shapiro-Wilk donne une probabilité de dépassement de 0.0001055, inférieure au seuil de signification de 5%. L'hypothèse de normalité de reading.score est donc rejetée.
```{r}
shapiro.test(studentPerf$writing.score)
```
Le test de Shapiro-Wilk donne une probabilité de dépassement de 2.922e-05, inférieure au seuil de signification de 5%. L'hypothèse de normalité de writing.score est donc rejetée.

NOTE : Les données ne sont pas normales d'après le test de Shapiro-Wilk mais on fera tout de même un test ANOVA sur les données, ce test étant robuste même si les données ne sont pas tout à fait normales.


2)Test d'homoscédasticité
```{r}
bartlett.test(math.score~gender,data=studentPerf)
```
p-value = 0.08995 > 5% => On rejette H0, on ne rejette donc pas l’hypothèse d’homoscédasticité pour math.score.
```{r}
bartlett.test(reading.score~gender,data=studentPerf)
```
p-value = 0.4818 > 5% => On ne rejette pas H0, on ne rejette donc pas l’hypothèse d’homoscédasticité pour reading.score.
```{r}
bartlett.test(writing.score~gender,data=studentPerf)
```
p-value = 0.2603 > 5% => On ne rejette pas H0, on ne rejette donc pas l’hypothèse d’homoscédasticité pour writing.score.

Les variances des trois scores sont donc homogènes.

Analyse multivariée des scores en fonction du genre

```{r}
cols = names(studentPerf)
def.par <-par(no.readonly=T)
par(mfrow=c(1,3))
for(i in 6:8) {
  plot(studentPerf[,i]~studentPerf$gender, xlab = "gender", ylab = cols[i])
}
```

Il semble y avoir une différence notable entre les hommes et les femmes pour les scores reading.score et writing.score.
Il semble aussi qu'il y a une légère différence pour le score math.score en fonction du genre. 
Pour confirmer ou infirmer ces résultats, nous effectuons des ANOVA:
Ici et dans la suite du projet, nous fixerons le seuil alpha* à 5%
```{r}
for(i in 6:8) {
  model = lm(studentPerf[,i]~1+gender, data = studentPerf)
  print(anova(model))
}
```
ANOVA sur math.score en fonction de gender : p-value = 9.12e-08 < 5% => on rejette H0. 
ANOVA sur reading.score en fonction de gender : p-value = 4.681e-15 < 5% => on rejette H0. 
ANOVA sur writing.score en fonction de gender : p-value = 2.2e-16 < 5% => on rejette H0. 
Il y a donc une différence significative entre les hommes et les femmes pour chacun des scores: math.score, reading.score et writing.score.

Analyse multivariée des scores en fonction du groupe ethnique
```{r}
cols = names(studentPerf)
def.par <-par(no.readonly=T)
par(mfrow=c(1,3))
for(i in 6:8) {
  plot(studentPerf[,i]~studentPerf$race.ethnicity, xlab = "race.ethnicity", ylab = cols[i])
}
```

Pour chacun des 3 scores, il semble y avoir des différences en fonction de l'ethnie de l'étudiant.
Les scores semblent être d'autant plus élévés que l'étudiant appartient au groupe E, puis D etc. jusqu'au groupe A dont 
les scores semblent êtres les moins élevés.

Pour confirmer ou infirmer ces résultats, nous effectuons des ANOVA:
```{r}
for(i in 6:8) {
  model = lm(studentPerf[,i]~1+race.ethnicity, data = studentPerf)
  print(anova(model))
}
```

ANOVA sur math.score en fonction de race.ethnicity : p-value = 1.373e-11 < 5% => on rejette H0. 
ANOVA sur reading.score en fonction de race.ethnicity : p-value = 0.000178 < 5% => on rejette H0. 
ANOVA sur writing.score en fonction de race.ethnicity : p-value = 1.098e-05 < 5% => on rejette H0. 
Il y a donc une différence significative entre les groupes d'ethnie différente pour chacun des scores: math.score, reading.score et writing.score.


Analyse multivariée des scores en fonction du niveau d'éducation des parents
```{r}
cols = names(studentPerf)
def.par <-par(no.readonly=T)
par(mfrow=c(1,3))
for(i in 6:8) {
  plot(studentPerf[,i]~studentPerf$parental.level.of.education, xlab = "parental.level.of.education", ylab = cols[i])
}
```
Pour chacun des 3 scores, les scores des étudiants dont le niveau d'éducation des parents 
correspond à high school ou some high school (ce qui correspond au niveau bac) semblent se détacher avec des scores plus faibles en général. 
Pour confirmer ou infirmer ces résultats, nous effectuons des ANOVA :
```{r}
for(i in 6:8) {
  model = lm(studentPerf[,i]~1+parental.level.of.education, data = studentPerf)
  print(anova(model))
}
```


ANOVA sur math.score en fonction de parental.level.of.education : p-value = 5.592e-06 < 5% => on rejette H0. 
ANOVA sur reading.score en fonction de parental.level.of.education : p-value = 1.168e-08 < 5% => on rejette H0. 
ANOVA sur writing.score en fonction de parental.level.of.education : p-value = 1.12e-13 < 5% => on rejette H0. 
Il y a donc une différence significative entre les groupes de niveau d'éducation des parents est différent pour chacun des scores: math.score, reading.score et writing.score.


#Analyse multivariée des scores en fonction du type de déjeuner (gratuit/tarif réduit ou standard)
```{r}
cols = names(studentPerf)
def.par <-par(no.readonly=T)
par(mfrow=c(1,3))
for(i in 6:8) {
  plot(studentPerf[,i]~studentPerf$lunch, xlab = "lunch", ylab = cols[i])
}
```

Pour chacun des 3 scores, il semble y avoir une différence notable en fonction du déjeuner.
Ceux ayant un déjeuner standard semblent avoir de meilleurs résultat.
Interessant de voir corrélation entre type de déjeuner et niveau éducation parents car le problème vient peut etre du niveau d'éducation des parents.
Pour confirmer ou infirmer ces résultats, nous effectuons des ANOVA:
```{r}
for(i in 6:8) {
  model = lm(studentPerf[,i]~1+lunch, data = studentPerf)
  print(anova(model))
}
```

ANOVA sur math.score en fonction de lunch : p-value = 2.2e-16 < 5% => on rejette H0. 
ANOVA sur reading.score en fonction de lunch : p-value = 2.003e-13 < 5% => on rejette H0. 
ANOVA sur writing.score en fonction de lunch : p-value = 3.186e-15 < 5% => on rejette H0. 
Il y a donc une différence significative entre les groupes qui ont un déjeuner gratuit/réduit ou bien standard pour chacun des scores: math.score, reading.score et writing.score.


Analyse multivariée des scores en fonction de si l'étudiant a complété ou non un test suite à un cours de préparation
```{r}
cols = names(studentPerf)
def.par <-par(no.readonly=T)
par(mfrow=c(1,3))
for(i in 6:8) {
  plot(studentPerf[,i]~studentPerf$test.preparation.course, xlab = "test.preparation.course", ylab = cols[i])
}
```
Pour chacun des 3 scores, il semble y avoir une différence notable entre les étudiants ayant passés un test préparatoire ou non.
Ceux ayant passés un test semblent avoir de meilleurs scores.
Pour confirmer ou infirmer ces résultats, nous effectuons des ANOVA:
```{r}
for(i in 6:8) {
  model = lm(studentPerf[,i]~1+test.preparation.course, data = studentPerf)
  print(anova(model))
}
```

ANOVA sur math.score en fonction de test.preparation.course : p-value = 1.536e-08 < 5% => on rejette H0. 
ANOVA sur reading.score en fonction de test.preparation.course : p-value = 9.082e-15 < 5% => on rejette H0. 
ANOVA sur writing.score en fonction de test.preparation.course : p-value = 2.2e-16 < 5% => on rejette H0. 
Il y a donc une différence significative entre les groupes qui ont passé un test de préparation ou non pour chacun des scores: math.score, reading.score et writing.score.

```{r}
corMat = cor(studentPerf[,c("math.score","reading.score", "writing.score")])
corMat
```

```{r}
pairs(studentPerf[,c("math.score","reading.score", "writing.score")],main = "Student Performance / Gender - Graphes de dispersion" ,col =c("blue","orange")[studentPerf$gender])
```
```{r}
pairs(studentPerf[,c("math.score","reading.score", "writing.score")],main = "Student Performance / Lunch - Graphes de dispersion" ,col =c("blue","orange")[studentPerf$lunch])
```

Les variables relatives aux scores semblent être corrélées en particulier "reading.score" et "writing.score"
Ceci indique qu'un étudiant a en général des scores assez homogènes aux trois épreuves et surtout en reading et writing.

On remarque également que deux groupes apparaissent losqu'on projettent les scores fonction du genre.

On effectue alors une ACP afin d'obtenir des variables non corrélées linéairement.
On effectue une ACP sur les variables quantitatives
```{r}
studentPerf.acp = princomp(studentPerf[,c("math.score","reading.score", "writing.score")])
biplot(studentPerf.acp)
```
L'orientation des flèches confirment que reading.score et writing.score sont très corrélées.

```{r}
summary(studentPerf.acp)
```
On pourrait choisir de perdre l'information du troisième axe factoriel. Cela dit, nous avons choisi de garder les 3 variables initiales (avant l'ACP), le jeu de données étant déjà assez simple. Ceci a l'avantage de conserver la signification de chacun des scores.



<!-- #L'ACP donne 3 composantes principales, la variance expliquée cumulée des deux premières est d'environ 98,5% -->
<!-- #On choisit de perdre l'information du troisième axe factoriel -->
<!-- #Les deux nouvelles variables que l'on appelera "score1" et "score2" résument l'information des 3 variables utilisées pour l'ACP  -->

<!-- #On remplace les 3 variables initiales par les deux nouvelles variable obtenues par l'ACP de variance expliquée maximale -->
<!-- score1 = studentPerf.acp$scores[,1] -->
<!-- score2 = studentPerf.acp$scores[,2] -->
<!-- studentPerfAcp <- cbind(studentPerf[,1:5],score1,score2) -->

classification automatique

CAH (nous servira surtout à determiner le nombre de classes K à utiliser pour appliquer l'algorithme des k-means afin d'essayer de faire une classification (clustering))

centrage réduction des données pour réduire influence sur les résulats causée par des variables à forte variance
```{r}
#studentPerf$math.score = scale(studentPerf$math.score)
#studentPerf$reading.score = scale(studentPerf$reading.score)
#studentPerf$writing.score = scale(studentPerf$writing.score)
```

```{r}
d.studentPerf = dist(studentPerf[,c(6:8)])
cah.ward = hclust(d.studentPerf,method="ward.D2")
plot(cah.ward, labels = F)
rect.hclust(cah.ward,k=2)
```
```{r}
plot(cah.ward, labels = F)
rect.hclust(cah.ward,k=4)
```
Etant donné ce dendogramme, il parait judicieux de prendre un niveau de regroupement tel qu'il y ait 2 ou 4 classes distinctes. 

Nous appliquons alors l'algorithme des k-means avec k=2, nstart=25 pour prendre 25 configurations initiales et garder la meilleure.
```{r}
kmeans(studentPerf[,c(6:8)], centers = 2, nstart=25)
```

```{r}
kmeans(studentPerf[,c(6:8)], centers = 4, nstart=25)
```
Les clusters ainsi formés donnent des groupes de niveaux différents que l'on pourrait nommer "moyen", "bon" "très bon" et "excellent".
